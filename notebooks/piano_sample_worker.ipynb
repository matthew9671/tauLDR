{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c932cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "# sys.path.remove(\"/home/users/yixiuz/.local/lib/python3.9/site-packages\")\n",
    "sys.path.append(\"/home/groups/swl1/yixiuz/torch_fid/lib/python3.9/site-packages\")\n",
    "sys.path.append(\"/home/groups/swl1/yixiuz/torch_fid/bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b040a5d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7592bcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-20 21:43:15.691735: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-20 21:43:15.804940: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /share/software/user/open/cudnn/8.9.0.131/lib:/usr/lib64/nvidia:/share/software/user/open/cuda/12.2.0/targets/x86_64-linux/lib:/share/software/user/open/cuda/12.2.0/lib64:/share/software/user/open/cuda/12.2.0/nvvm/lib64:/share/software/user/open/cuda/12.2.0/extras/Debugger/lib64:/share/software/user/open/cuda/12.2.0/extras/CUPTI/lib64:/share/software/user/open/python/3.9.0/lib:/share/software/user/open/libffi/3.2.1/lib64:/share/software/user/open/sqlite/3.44.2/lib:/share/software/user/open/readline/8.2/lib:/share/software/user/open/ncurses/6.4/lib:/share/software/user/open/tcltk/8.6.6/lib:/share/software/user/open/libressl/3.2.1/lib:/share/software/user/open/zlib/1.2.11/lib\n",
      "2024-05-20 21:43:15.804977: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-20 21:43:16.734812: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /share/software/user/open/cudnn/8.9.0.131/lib:/usr/lib64/nvidia:/share/software/user/open/cuda/12.2.0/targets/x86_64-linux/lib:/share/software/user/open/cuda/12.2.0/lib64:/share/software/user/open/cuda/12.2.0/nvvm/lib64:/share/software/user/open/cuda/12.2.0/extras/Debugger/lib64:/share/software/user/open/cuda/12.2.0/extras/CUPTI/lib64:/share/software/user/open/python/3.9.0/lib:/share/software/user/open/libffi/3.2.1/lib64:/share/software/user/open/sqlite/3.44.2/lib:/share/software/user/open/readline/8.2/lib:/share/software/user/open/ncurses/6.4/lib:/share/software/user/open/tcltk/8.6.6/lib:/share/software/user/open/libressl/3.2.1/lib:/share/software/user/open/zlib/1.2.11/lib\n",
      "2024-05-20 21:43:16.734962: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /share/software/user/open/cudnn/8.9.0.131/lib:/usr/lib64/nvidia:/share/software/user/open/cuda/12.2.0/targets/x86_64-linux/lib:/share/software/user/open/cuda/12.2.0/lib64:/share/software/user/open/cuda/12.2.0/nvvm/lib64:/share/software/user/open/cuda/12.2.0/extras/Debugger/lib64:/share/software/user/open/cuda/12.2.0/extras/CUPTI/lib64:/share/software/user/open/python/3.9.0/lib:/share/software/user/open/libffi/3.2.1/lib64:/share/software/user/open/sqlite/3.44.2/lib:/share/software/user/open/readline/8.2/lib:/share/software/user/open/ncurses/6.4/lib:/share/software/user/open/tcltk/8.6.6/lib:/share/software/user/open/libressl/3.2.1/lib:/share/software/user/open/zlib/1.2.11/lib\n",
      "2024-05-20 21:43:16.734974: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import ml_collections\n",
    "\n",
    "import lib.utils.bookkeeping as bookkeeping\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lib.utils.utils as utils\n",
    "import lib.models.models as models\n",
    "import lib.models.model_utils as model_utils\n",
    "import lib.datasets.datasets as datasets\n",
    "import lib.datasets.dataset_utils as dataset_utils\n",
    "import lib.sampling.sampling as sampling\n",
    "import lib.sampling.sampling_utils as sampling_utils\n",
    "\n",
    "import config.eval.piano_hollow as piano\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "eval_cfg = piano.get_config()\n",
    "train_cfg = bookkeeping.load_ml_collections(Path(eval_cfg.train_config_path))\n",
    "\n",
    "for item in eval_cfg.train_config_overrides:\n",
    "    utils.set_in_nested_dict(train_cfg, item[0], item[1])\n",
    "\n",
    "S = train_cfg.data.S\n",
    "# device = torch.device(eval_cfg.device)\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = model_utils.create_model(train_cfg, device)\n",
    "\n",
    "loaded_state = torch.load(Path(eval_cfg.checkpoint_path),\n",
    "    map_location=device)\n",
    "\n",
    "modified_model_state = utils.remove_module_from_keys(loaded_state['model'])\n",
    "model.load_state_dict(modified_model_state)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "dataset = dataset_utils.get_dataset(eval_cfg, device)\n",
    "data = dataset.data\n",
    "test_dataset = np.load(eval_cfg.sampler.test_dataset)\n",
    "condition_dim = eval_cfg.sampler.condition_dim\n",
    "descramble_key = np.loadtxt(eval_cfg.pianoroll_dataset_path + '/descramble_key.txt')\n",
    "# The mask stays the same\n",
    "descramble_key = np.concatenate([descramble_key, np.array([descramble_key.shape[0]])], axis=0)\n",
    "\n",
    "def descramble(samples):\n",
    "    return descramble_key[samples.flatten()].reshape(*samples.shape)\n",
    "\n",
    "descrambled_test_dataset = descramble(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7f22528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval import outliers, get_dist, hellinger, eval_mse_stats, save_results\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b30a20d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(num_repeats, sample_size, batch_size, \n",
    "                    results_file,\n",
    "                   method, g_steps, tau_steps, \n",
    "                    c_steps, c_stepsize, corrector):\n",
    "    \n",
    "    tqdm._instances.clear()\n",
    "\n",
    "    # Specific to each method\n",
    "    eval_cfg.sampler.num_steps = tau_steps\n",
    "    eval_cfg.sampler.updates_per_eval = g_steps\n",
    "    \n",
    "    # Generic corrector fields\n",
    "    eval_cfg.sampler.num_corrector_steps = c_steps\n",
    "    eval_cfg.sampler.corrector_entry_time = 0.9\n",
    "    eval_cfg.sampler.corrector_step_size_multiplier = c_stepsize\n",
    "    eval_cfg.sampler.balancing_function = corrector\n",
    "\n",
    "    if method == \"gillespies\":\n",
    "        eval_cfg.sampler.name = \"ConditionalPCMultiGillespies\"\n",
    "    elif method == \"tauleaping\":\n",
    "        eval_cfg.sampler.name = \"ConditionalPCTauLeapingAbsorbingInformed\"\n",
    "    else:\n",
    "        assert(False)\n",
    "\n",
    "    sampler = sampling_utils.get_sampler(eval_cfg)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    test_size = sample_size\n",
    "    \n",
    "    for _ in range(num_repeats):\n",
    "        \n",
    "        h_dists = []\n",
    "        outlier_rates = []\n",
    "        for start in range(0, test_size, batch_size):\n",
    "            end = min(start + batch_size, test_size)\n",
    "            size = end - start\n",
    "\n",
    "            conditioner = torch.from_numpy(test_dataset[start:end, :condition_dim]).to(device)\n",
    "            samples, out = sampler.sample(model, size, 0, conditioner)\n",
    "            # !Important to descramble!\n",
    "            samples = descramble(samples)\n",
    "\n",
    "            for i in range(size):\n",
    "                h = hellinger(descrambled_test_dataset[start+i, :], samples[i, :], S)\n",
    "                r = outliers(descrambled_test_dataset[start+i, :], samples[i, :], S)\n",
    "                h_dists.append(h)\n",
    "                outlier_rates.append(r)\n",
    "        # !\n",
    "        D = eval_cfg.data.shape[0] - eval_cfg.sampler.condition_dim\n",
    "        if method == \"gillespies\":\n",
    "            nfe = D / eval_cfg.sampler.updates_per_eval\n",
    "        elif method == \"tauleaping\":\n",
    "            nfe = eval_cfg.sampler.num_steps\n",
    "        nfe += nfe * eval_cfg.sampler.corrector_entry_time * eval_cfg.sampler.num_corrector_steps\n",
    "\n",
    "        new_result = {\n",
    "                'method': method,\n",
    "                'g_steps': 0 if method != \"gillespies\" else eval_cfg.sampler.updates_per_eval,\n",
    "                'tau_steps': 0 if method != \"tauleaping\" else eval_cfg.sampler.num_steps,\n",
    "                'use_corrector': eval_cfg.sampler.corrector_entry_time > 0 \n",
    "                             and eval_cfg.sampler.num_corrector_steps > 0,\n",
    "                'corrector': eval_cfg.sampler.balancing_function,\n",
    "                'c_stepsize': eval_cfg.sampler.corrector_step_size_multiplier,\n",
    "                'c_steps': eval_cfg.sampler.num_corrector_steps,\n",
    "                'nfe': nfe,\n",
    "                'h_dist': np.mean(h_dists),\n",
    "                'outlier_rate': np.mean(outlier_rates),\n",
    "            }\n",
    "        print(new_result)\n",
    "        results.append(new_result)\n",
    "\n",
    "    save_results(results, results_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19cfadf4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:01, 33.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'tauleaping', 'g_steps': 0, 'tau_steps': 50, 'use_corrector': True, 'corrector': 'mpf', 'c_stepsize': 1.0, 'c_steps': 2, 'nfe': 140.0, 'h_dist': 0.2668313174703481, 'outlier_rate': 0.083203125}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:01, 37.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'tauleaping', 'g_steps': 0, 'tau_steps': 50, 'use_corrector': True, 'corrector': 'mpf', 'c_stepsize': 1.0, 'c_steps': 2, 'nfe': 140.0, 'h_dist': 0.2600486274351373, 'outlier_rate': 0.082421875}\n",
      "Experiment results saved to  piano_results_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:01, 37.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'tauleaping', 'g_steps': 0, 'tau_steps': 50, 'use_corrector': True, 'corrector': 'barker', 'c_stepsize': 1.0, 'c_steps': 2, 'nfe': 140.0, 'h_dist': 0.2857392213506149, 'outlier_rate': 0.09921875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:01, 37.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'tauleaping', 'g_steps': 0, 'tau_steps': 50, 'use_corrector': True, 'corrector': 'barker', 'c_stepsize': 1.0, 'c_steps': 2, 'nfe': 140.0, 'h_dist': 0.29041439957098325, 'outlier_rate': 0.095703125}\n",
      "Experiment results saved to  piano_results_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:01, 37.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'tauleaping', 'g_steps': 0, 'tau_steps': 50, 'use_corrector': True, 'corrector': 'birthdeath', 'c_stepsize': 0.1, 'c_steps': 2, 'nfe': 140.0, 'h_dist': 0.3186536161480142, 'outlier_rate': 0.1296875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:01, 37.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'tauleaping', 'g_steps': 0, 'tau_steps': 50, 'use_corrector': True, 'corrector': 'birthdeath', 'c_stepsize': 0.1, 'c_steps': 2, 'nfe': 140.0, 'h_dist': 0.28446260233681525, 'outlier_rate': 0.10859375}\n",
      "Experiment results saved to  piano_results_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:02, 106.60it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'gillespies', 'g_steps': 3, 'tau_steps': 0, 'use_corrector': True, 'corrector': 'mpf', 'c_stepsize': 1.0, 'c_steps': 2, 'nfe': 209.06666666666666, 'h_dist': 0.42027543564354497, 'outlier_rate': 0.0859375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:02, 108.07it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'gillespies', 'g_steps': 3, 'tau_steps': 0, 'use_corrector': True, 'corrector': 'mpf', 'c_stepsize': 1.0, 'c_steps': 2, 'nfe': 209.06666666666666, 'h_dist': 0.3994891652684006, 'outlier_rate': 0.08984375}\n",
      "Experiment results saved to  piano_results_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:02, 108.01it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'gillespies', 'g_steps': 3, 'tau_steps': 0, 'use_corrector': True, 'corrector': 'barker', 'c_stepsize': 1.0, 'c_steps': 2, 'nfe': 209.06666666666666, 'h_dist': 0.29192670713085234, 'outlier_rate': 0.091796875}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:02, 107.84it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'gillespies', 'g_steps': 3, 'tau_steps': 0, 'use_corrector': True, 'corrector': 'barker', 'c_stepsize': 1.0, 'c_steps': 2, 'nfe': 209.06666666666666, 'h_dist': 0.289521658416117, 'outlier_rate': 0.087890625}\n",
      "Experiment results saved to  piano_results_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:02, 107.72it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'gillespies', 'g_steps': 3, 'tau_steps': 0, 'use_corrector': True, 'corrector': 'birthdeath', 'c_stepsize': 0.1, 'c_steps': 2, 'nfe': 209.06666666666666, 'h_dist': 0.2763986583731081, 'outlier_rate': 0.093359375}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "225it [00:02, 108.37it/s]                         "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'gillespies', 'g_steps': 3, 'tau_steps': 0, 'use_corrector': True, 'corrector': 'birthdeath', 'c_stepsize': 0.1, 'c_steps': 2, 'nfe': 209.06666666666666, 'h_dist': 0.2865092655555353, 'outlier_rate': 0.087890625}\n",
      "Experiment results saved to  piano_results_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results_file = 'piano_results_test.csv'\n",
    "\n",
    "num_repeats = 2\n",
    "sample_size = 10\n",
    "batch_size = 10\n",
    "\n",
    "methods = [\"tauleaping\", \n",
    "           \"gillespies\"]\n",
    "\n",
    "updates_per_evals = [3, 2, 1]\n",
    "num_sample_steps = [50, 100, 200]\n",
    "\n",
    "correctors = [\"mpf\", \"barker\", \"birthdeath\"]\n",
    "corrector_stepsizes = [1.0, 1.0, 0.1]\n",
    "corrector_steps = 2\n",
    "\n",
    "for method in methods:\n",
    "    for i in range(len(correctors)):\n",
    "        corrector = correctors[i]\n",
    "        c_stepsize = corrector_stepsizes[i]\n",
    "        g_steps = updates_per_evals[0]\n",
    "        tau_steps = num_sample_steps[0]\n",
    "        c_steps = corrector_steps\n",
    "        run_experiments(num_repeats=num_repeats, \n",
    "                        sample_size=sample_size, batch_size=batch_size,\n",
    "                        results_file=results_file,\n",
    "                        method=method, \n",
    "                        g_steps=g_steps, \n",
    "                        tau_steps=tau_steps, \n",
    "                        c_steps=c_steps, \n",
    "                        c_stepsize=c_stepsize, \n",
    "                        corrector=corrector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7d256f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:06,  8.10it/s]\n",
      "49it [00:06,  8.11it/s]\n",
      "49it [00:06,  8.10it/s]\n",
      "49it [00:06,  8.11it/s]\n",
      "49it [00:05,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'tauleaping', 'g_steps': 0, 'tau_steps': 50, 'use_corrector': True, 'corrector': 'mpf', 'c_stepsize': 1.0, 'c_steps': 1, 'nfe': 95.0, 'h_dist': 0.3794871595882483, 'outlier_rate': 0.12499197070914697}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:06,  8.11it/s]\n",
      "49it [00:06,  8.10it/s]\n",
      "49it [00:06,  8.11it/s]\n",
      "49it [00:06,  8.11it/s]\n",
      "49it [00:05,  9.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'tauleaping', 'g_steps': 0, 'tau_steps': 50, 'use_corrector': True, 'corrector': 'mpf', 'c_stepsize': 1.0, 'c_steps': 1, 'nfe': 95.0, 'h_dist': 0.3780450319462578, 'outlier_rate': 0.12188062050359712}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49it [00:06,  8.11it/s]\n",
      "49it [00:06,  8.11it/s]\n",
      "49it [00:06,  8.10it/s]\n",
      "49it [00:06,  8.11it/s]\n",
      "49it [00:05,  9.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'tauleaping', 'g_steps': 0, 'tau_steps': 50, 'use_corrector': True, 'corrector': 'mpf', 'c_stepsize': 1.0, 'c_steps': 1, 'nfe': 95.0, 'h_dist': 0.3792639253193196, 'outlier_rate': 0.12286420863309352}\n",
      "Experiment results saved to  piano_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [00:12,  8.06it/s]\n",
      "99it [00:12,  8.06it/s]\n",
      "99it [00:12,  8.06it/s]\n",
      "99it [00:12,  8.05it/s]\n",
      "99it [00:10,  9.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'tauleaping', 'g_steps': 0, 'tau_steps': 100, 'use_corrector': True, 'corrector': 'mpf', 'c_stepsize': 1.0, 'c_steps': 1, 'nfe': 190.0, 'h_dist': 0.38032061559315516, 'outlier_rate': 0.12338209789311408}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [00:12,  8.06it/s]\n",
      "99it [00:12,  8.06it/s]\n",
      "99it [00:12,  8.06it/s]\n",
      "99it [00:12,  8.06it/s]\n",
      "99it [00:10,  9.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'method': 'tauleaping', 'g_steps': 0, 'tau_steps': 100, 'use_corrector': True, 'corrector': 'mpf', 'c_stepsize': 1.0, 'c_steps': 1, 'nfe': 190.0, 'h_dist': 0.3800044233128485, 'outlier_rate': 0.12243464157245632}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "99it [00:12,  8.06it/s]\n",
      "99it [00:12,  8.06it/s]\n",
      "99it [00:12,  8.06it/s]\n",
      "53it [00:06,  7.61it/s]"
     ]
    }
   ],
   "source": [
    "results_file = 'piano_results.csv'\n",
    "\n",
    "num_repeats = 3\n",
    "sample_size = test_dataset.shape[0]\n",
    "batch_size = 200\n",
    "\n",
    "methods = [\"tauleaping\", \n",
    "           \"gillespies\"]\n",
    "\n",
    "updates_per_evals = [3, 2, 1]\n",
    "num_sample_steps = [50, 100, 200]\n",
    "\n",
    "correctors = [\"mpf\", \"barker\", \"birthdeath\"]\n",
    "corrector_stepsizes = [1.0, 1.0, 0.1]\n",
    "corrector_steps = 1\n",
    "\n",
    "# 1 corrector step\n",
    "c_steps = 1\n",
    "for method in methods:\n",
    "    for i in range(len(correctors)):\n",
    "        \n",
    "        corrector = correctors[i]\n",
    "        c_stepsize = corrector_stepsizes[i]\n",
    "        \n",
    "        for j in range(len(updates_per_evals)):\n",
    "        \n",
    "            g_steps = updates_per_evals[j]\n",
    "            tau_steps = num_sample_steps[j]\n",
    "            \n",
    "            run_experiments(num_repeats=num_repeats, \n",
    "                            sample_size=sample_size, batch_size=batch_size,\n",
    "                            results_file=results_file,\n",
    "                            method=method, \n",
    "                            g_steps=g_steps, \n",
    "                            tau_steps=tau_steps, \n",
    "                            c_steps=c_steps, \n",
    "                            c_stepsize=c_stepsize, \n",
    "                            corrector=corrector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980fee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different rates\n",
    "correctors = [\"mpf\", \"barker\"]\n",
    "corrector_stepsizes = [0.1, 0.1]\n",
    "\n",
    "for method in methods:\n",
    "    for i in range(len(correctors)):\n",
    "        \n",
    "        corrector = correctors[i]\n",
    "        c_stepsize = corrector_stepsizes[i]\n",
    "        \n",
    "        for j in range(len(updates_per_evals)):\n",
    "        \n",
    "            g_steps = updates_per_evals[j]\n",
    "            tau_steps = num_sample_steps[j]\n",
    "            \n",
    "            run_experiments(num_repeats=num_repeats, \n",
    "                            sample_size=sample_size, \n",
    "                            results_file=results_file,\n",
    "                            method=method, \n",
    "                            g_steps=g_steps, \n",
    "                            tau_steps=tau_steps, \n",
    "                            c_steps=c_steps, \n",
    "                            c_stepsize=c_stepsize, \n",
    "                            corrector=corrector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c06270",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
