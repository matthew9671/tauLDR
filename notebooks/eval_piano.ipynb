{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "# sys.path.remove(\"/home/users/yixiuz/.local/lib/python3.9/site-packages\")\n",
    "sys.path.append(\"/home/groups/swl1/yixiuz/torch_fid/lib/python3.9/site-packages\")\n",
    "sys.path.append(\"/home/groups/swl1/yixiuz/torch_fid/bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config.eval.piano_hollow' from '../config/eval/piano_hollow.py'>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "\n",
    "reload(piano)\n",
    "# reload(sampling_utils)\n",
    "# reload(sampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/224 [10:10<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'AbsorbingHollowSequenceTransformerFlash'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26075/422548737.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_cfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m loaded_state = torch.load(Path(eval_cfg.checkpoint_path),\n",
      "\u001b[0;32m/home/groups/swl1/yixiuz/torch_fid/tauLDR/lib/models/model_utils.py\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(cfg, device, rank)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/swl1/yixiuz/torch_fid/tauLDR/lib/models/model_utils.py\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_MODELS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AbsorbingHollowSequenceTransformerFlash'"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import ml_collections\n",
    "\n",
    "import config.eval.piano_hollow as piano\n",
    "import lib.utils.bookkeeping as bookkeeping\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import lib.utils.utils as utils\n",
    "import lib.models.models as models\n",
    "import lib.models.model_utils as model_utils\n",
    "import lib.datasets.datasets as datasets\n",
    "import lib.datasets.dataset_utils as dataset_utils\n",
    "import lib.sampling.sampling as sampling\n",
    "import lib.sampling.sampling_utils as sampling_utils\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "eval_cfg = piano.get_config()\n",
    "train_cfg = bookkeeping.load_ml_collections(Path(eval_cfg.train_config_path))\n",
    "\n",
    "for item in eval_cfg.train_config_overrides:\n",
    "    utils.set_in_nested_dict(train_cfg, item[0], item[1])\n",
    "\n",
    "S = train_cfg.data.S\n",
    "# device = torch.device(eval_cfg.device)\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "model = model_utils.create_model(train_cfg, device)\n",
    "\n",
    "loaded_state = torch.load(Path(eval_cfg.checkpoint_path),\n",
    "    map_location=device)\n",
    "\n",
    "modified_model_state = utils.remove_module_from_keys(loaded_state['model'])\n",
    "model.load_state_dict(modified_model_state)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "dataset = dataset_utils.get_dataset(eval_cfg, device)\n",
    "data = dataset.data\n",
    "test_dataset = np.load(eval_cfg.sampler.test_dataset)\n",
    "condition_dim = eval_cfg.sampler.condition_dim\n",
    "descramble_key = np.loadtxt(eval_cfg.pianoroll_dataset_path + '/descramble_key.txt')\n",
    "# The mask stays the same\n",
    "descramble_key = np.concatenate([descramble_key, np.array([descramble_key.shape[0]])], axis=0)\n",
    "\n",
    "def descramble(samples):\n",
    "    return descramble_key[samples.flatten()].reshape(*samples.shape)\n",
    "\n",
    "descrambled_test_dataset = descramble(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "checkpoint_path: /home/groups/swl1/yixiuz/torch_fid/experiments/piano/2024-05-14/00-36-56_piano_absorbing_hollow/checkpoints/ckpt_0000999999.pt\n",
       "data:\n",
       "  S: 130\n",
       "  batch_size: 64\n",
       "  name: LakhPianoroll\n",
       "  path: /home/groups/swl1/yixiuz/torch_fid/downloads/pianoroll_dataset/train.npy\n",
       "  shape:\n",
       "  - 256\n",
       "  shuffle: true\n",
       "device: cpu\n",
       "eval_name: piano\n",
       "pianoroll_dataset_path: /home/groups/swl1/yixiuz/torch_fid/downloads/pianoroll_dataset\n",
       "sampler:\n",
       "  balancing_function: mpf\n",
       "  condition_dim: 32\n",
       "  corrector_entry_time: 0.9\n",
       "  corrector_step_size_multiplier: 0.1\n",
       "  eps_ratio: 1.0e-09\n",
       "  initial_dist: absorbing\n",
       "  min_t: 0.01\n",
       "  name: ConditionalPCTauLeapingAbsorbingInformed\n",
       "  num_corrector_steps: 2\n",
       "  num_steps: 1000\n",
       "  reject_multiple_jumps: true\n",
       "  test_dataset: /home/groups/swl1/yixiuz/torch_fid/downloads/pianoroll_dataset/test.npy\n",
       "train_config_overrides:\n",
       "- - - device\n",
       "  - cpu\n",
       "- - - data\n",
       "    - path\n",
       "  - /home/groups/swl1/yixiuz/torch_fid/downloads/pianoroll_dataset/train.npy\n",
       "- - - distributed\n",
       "  - false\n",
       "train_config_path: /home/groups/swl1/yixiuz/torch_fid/experiments/piano/2024-05-14/00-36-56_piano_absorbing_hollow/config/config_001.yaml"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.sampling.sampling import compute_backward, get_initial_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange, tqdm\n",
    "\n",
    "class ConditionalGillespies():\n",
    "    def __init__(self, cfg):\n",
    "        self.cfg =cfg\n",
    "\n",
    "    def sample(self, model, N, num_intermediates, conditioner, updates_per_eval=1):\n",
    "        assert conditioner.shape[0] == N\n",
    "        \n",
    "        condition_dim = self.cfg.sampler.condition_dim\n",
    "        total_D = np.prod(self.cfg.data.shape)\n",
    "        D = total_D - condition_dim\n",
    "        \n",
    "        S = self.cfg.data.S\n",
    "        scfg = self.cfg.sampler\n",
    "        num_steps = scfg.num_steps\n",
    "        min_t = scfg.min_t\n",
    "        eps_ratio = scfg.eps_ratio\n",
    "        initial_dist = scfg.initial_dist\n",
    "        if initial_dist == 'gaussian':\n",
    "            initial_dist_std  = model.Q_sigma\n",
    "        else:\n",
    "            initial_dist_std = None\n",
    "        device = model.device\n",
    "        # Corrector stuff\n",
    "        num_corrector_steps = scfg.num_corrector_steps\n",
    "        corrector_step_size_multiplier = scfg.corrector_step_size_multiplier\n",
    "        corrector_entry_time = scfg.corrector_entry_time\n",
    "        if scfg.balancing_function == \"barker\":\n",
    "            balancing_function = lambda score: score / (1 + score) \n",
    "        elif scfg.balancing_function == \"mpf\":\n",
    "            balancing_function = lambda score: torch.sqrt(score)\n",
    "        elif scfg.balancing_function == \"birthdeath\":\n",
    "            balancing_function = None\n",
    "        else:\n",
    "            print(\"Balancing function not found: \" + scfg.balancing_function)\n",
    "            return\n",
    "\n",
    "        # Now the batch is not syncronized anymore\n",
    "        ts = 1.0 * torch.ones((N,), device=device)\n",
    "        update_mask = ts > min_t\n",
    "        num_updates = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            x = get_initial_samples(N, D, device, S, initial_dist,\n",
    "                initial_dist_std)\n",
    "\n",
    "            x_hist = []\n",
    "            x0_hist = []\n",
    "\n",
    "            pbar = tqdm(total=D)\n",
    "            while num_updates < D:\n",
    "\n",
    "                # Compute backward transition rate\n",
    "                qt0 = model.transition(ts) # (N, S, S)\n",
    "                rate = model.rate(ts) # (N, S, S)\n",
    "\n",
    "                model_input = torch.concat((conditioner, x), dim=1)\n",
    "                p0t = F.softmax(model(model_input, ts), dim=2) # (N, D, S)\n",
    "                p0t = p0t[:, condition_dim:, :]\n",
    "\n",
    "                Rf, RfT, Rb, x_0max, scores = compute_backward(qt0, rate, p0t, x)\n",
    "                # Rb: (N, D, S)\n",
    "                Rb[torch.arange(N, device=device).repeat_interleave(D),\n",
    "                   torch.arange(D, device=device).repeat(N),\n",
    "                   x.long().flatten()] = eps_ratio\n",
    "            \n",
    "                # Compute total rate (N, D)\n",
    "                Rb_sum = torch.sum(Rb, axis=2)\n",
    "                # Sample a holding time (N, D)\n",
    "                taus = torch.distributions.Exponential(Rb_sum).sample()\n",
    "                # Find the position of the shortest holding time for each dimension (N,)\n",
    "                ids_sorted = torch.argsort(taus, axis=1)\n",
    "                dts = torch.zeros((N,), device=device)\n",
    "                \n",
    "                for update in range(updates_per_eval):\n",
    "                    # Make one round of updates\n",
    "                    ids = ids_sorted[:, update]\n",
    "                    # (N,)\n",
    "                    dts = taus[torch.arange(N, device=device), ids] - dts\n",
    "\n",
    "                    # Rates given the dimensions of transition (N, S)\n",
    "                    rates_single = Rb[torch.arange(N, device=device),ids]\n",
    "                    # Total rate given the dimensions of transition (N, 1)\n",
    "                    rates_sum_single = torch.unsqueeze(Rb_sum[torch.arange(N, device=device),ids], 1)\n",
    "                    # The targets of transition (N,)\n",
    "                    updates = torch.multinomial(rates_single / rates_sum_single, 1)[:,0]\n",
    "                    # Update ts\n",
    "                    update_mask = update_mask & ((ts - dts * update_mask) > min_t)\n",
    "                    ts -= dts * update_mask\n",
    "                    # Update x\n",
    "                    original = x[torch.arange(N, device=device), ids]\n",
    "                    x[torch.arange(N, device=device), ids] = updates * update_mask + original * (~update_mask)\n",
    "                    num_updates += 1\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "                # Corrector time\n",
    "                def get_rates(in_x, in_t):\n",
    "                    qt0 = model.transition(in_t) # (N, S, S)\n",
    "                    rate = model.rate(in_t) # (N, S, S)\n",
    "\n",
    "                    p0t = F.softmax(model(in_x, in_t), dim=2) # (N, D, S)\n",
    "\n",
    "                    denom_x = torch.ones_like(in_x) * (S-1)\n",
    "\n",
    "                    forward_rates, transpose_forward_rates, reverse_rates, x_0max, scores = compute_backward(qt0, rate, p0t, in_x, denom_x=denom_x, eps=eps_ratio)\n",
    "                    \n",
    "                    mask_positions = in_x == (S-1)\n",
    "                    nonmask_positions = ~mask_positions\n",
    "\n",
    "                    backward_score_to_curr = scores[\n",
    "                        torch.arange(N, device=device).repeat_interleave(D),\n",
    "                        torch.arange(D, device=device).repeat(N),\n",
    "                        in_x.long().flatten()\n",
    "                    ].view(N,D)\n",
    "                    forward_score_from_curr = 1 / (backward_score_to_curr * nonmask_positions + mask_positions)\n",
    "                    forward_score_from_curr *= nonmask_positions\n",
    "\n",
    "                    scores = scores * mask_positions.unsqueeze(2)\n",
    "                    scores[:,:,S-1] = forward_score_from_curr\n",
    "                    \n",
    "                    forward_rates[\n",
    "                        torch.arange(N, device=device).repeat_interleave(D),\n",
    "                        torch.arange(D, device=device).repeat(N),\n",
    "                        in_x.long().flatten()\n",
    "                    ] = 0.0 \n",
    "                    reverse_rates[\n",
    "                        torch.arange(N, device=device).repeat_interleave(D),\n",
    "                        torch.arange(D, device=device).repeat(N),\n",
    "                        in_x.long().flatten()\n",
    "                    ] = 0.0 \n",
    "                    \n",
    "#                     assert(not scores.isnan().any())\n",
    "#                     assert(not scores.isinf().any())\n",
    "                    \n",
    "                    return forward_rates, transpose_forward_rates, reverse_rates, x_0max, scores\n",
    "                    \n",
    "                def take_poisson_step(in_x, in_reverse_rates, in_h):\n",
    "                    diffs = torch.arange(S, device=device).view(1,1,S) - in_x.view(N,D,1)\n",
    "                    poisson_dist = torch.distributions.poisson.Poisson(in_reverse_rates * in_h)\n",
    "                    jump_nums = poisson_dist.sample()\n",
    "                    adj_diffs = jump_nums * diffs\n",
    "                    overall_jump = torch.sum(adj_diffs, dim=2)\n",
    "                    unclip_x_new = in_x + overall_jump\n",
    "                    x_new = torch.clamp(unclip_x_new, min=0, max=S-1)\n",
    "\n",
    "                    return x_new\n",
    "\n",
    "                if num_updates >= (1-corrector_entry_time) * D:\n",
    "                    \n",
    "                    h = 1/D\n",
    "                    \n",
    "                    for cstep in range(num_corrector_steps):\n",
    "                        forward_rates, transpose_forward_rates, reverse_rates, _, scores = get_rates(x, ts) # ts-h?\n",
    "                        if balancing_function is None:\n",
    "                            # We're using the default corrector\n",
    "                            # which corresponds to birth-death Stein operator\n",
    "                            corrector_rate = transpose_forward_rates + reverse_rates\n",
    "                        else:\n",
    "                            # We removed the one half here because it makes more sense for the absorbing\n",
    "                            corrector_rate = (transpose_forward_rates + forward_rates) * balancing_function(scores)\n",
    "                        # Only update dimensions with \n",
    "                        corrector_rate *= update_mask.unsqueeze(1).unsqueeze(1)\n",
    "                            \n",
    "                        corrector_rate[\n",
    "                            torch.arange(N, device=device).repeat_interleave(D),\n",
    "                            torch.arange(D, device=device).repeat(N),\n",
    "                            x.long().flatten()\n",
    "                        ] = eps_ratio\n",
    "                        \n",
    "                        x = take_poisson_step(x, corrector_rate, \n",
    "                            corrector_step_size_multiplier * h)\n",
    "                \n",
    "                \n",
    "            model_input = torch.concat((conditioner, x), dim=1)\n",
    "            p_0gt = F.softmax(model(model_input, min_t * torch.ones((N,), device=device)), dim=2) # (N, D, S)\n",
    "            p_0gt = p_0gt[:, condition_dim:, :]\n",
    "            \n",
    "            x_0max = torch.max(p_0gt, dim=2)[1]\n",
    "\n",
    "            mask_positions = x == (S-1)\n",
    "            nonmask_positions = ~mask_positions\n",
    "            samples = nonmask_positions * x + mask_positions * x_0max\n",
    "            \n",
    "            output = torch.concat((conditioner, samples), dim=1)\n",
    "            \n",
    "            return output.detach().cpu().numpy().astype(int), ts.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist(seq):\n",
    "    S = 129\n",
    "    L = seq.shape[0]\n",
    "    one_hot = np.zeros((L, S))\n",
    "    seq = np.array(seq, dtype=int)\n",
    "    one_hot[np.arange(L), seq] = 1\n",
    "    return np.sum(one_hot, axis=0) / L\n",
    "\n",
    "def get_mask(seq):\n",
    "    S = 129\n",
    "    L = seq.shape[0]\n",
    "    one_hot = np.zeros((L, S))\n",
    "    seq = np.array(seq, dtype=int)\n",
    "    one_hot[np.arange(L), seq] = 1\n",
    "    return 1 - np.prod(1 - one_hot, axis=0)\n",
    "\n",
    "def hellinger(seq1, seq2):\n",
    "    d1, d2 = get_dist(seq1), get_dist(seq2)\n",
    "    return np.sqrt(.5 * np.sum((d1 ** .5 - d2 ** .5) ** 2))\n",
    "\n",
    "def outliers(ref, sample):\n",
    "    ref_mask = get_mask(ref)\n",
    "    sample_dist = get_dist(sample)\n",
    "    return np.sum((1 - ref_mask) * sample_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 199/224 [00:02<00:00, 96.70it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26075/235320168.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_instances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0msampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConditionalGillespies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_cfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconditioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdescramble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_26075/364166374.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, model, N, num_intermediates, conditioner, updates_per_eval)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                 \u001b[0mmodel_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconditioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mp0t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (N, D, S)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mp0t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp0t\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcondition_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/swl1/yixiuz/torch_fid/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/swl1/yixiuz/torch_fid/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/swl1/yixiuz/torch_fid/tauLDR/lib/models/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, times)\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0mS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B, D, S)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/swl1/yixiuz/torch_fid/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/swl1/yixiuz/torch_fid/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/swl1/yixiuz/torch_fid/tauLDR/lib/networks/hollow_transformers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, times)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0;31m# for encoder_layer in self.encoder_layers:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble_encoder_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m             \u001b[0mxf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble_encoder_layers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers_per_mixed\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m                 \u001b[0mxb_flipped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/swl1/yixiuz/torch_fid/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/swl1/yixiuz/torch_fid/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1518\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1519\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1521\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/groups/swl1/yixiuz/torch_fid/tauLDR/lib/networks/hollow_transformers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x1, x2, temb)\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilm_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilm_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ff_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilm_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilm_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Sample with PC-multi-Gillespie's and evaluate\n",
    "num_samples = 5\n",
    "test_data_idx = 2\n",
    "conditioner = torch.from_numpy(test_dataset[test_data_idx, 0:condition_dim]).to(device).view(1, condition_dim)\n",
    "conditioner = conditioner.repeat(num_samples, 1)\n",
    "\n",
    "# play around with the sampler by overriding some configs\n",
    "eval_cfg.sampler.num_corrector_steps = 1\n",
    "eval_cfg.sampler.corrector_entry_time = 0.0\n",
    "eval_cfg.sampler.corrector_step_size_multiplier = .1\n",
    "eval_cfg.sampler.balancing_function = \"mpf\"\n",
    "\n",
    "tqdm._instances.clear()\n",
    "sampler = ConditionalGillespies(eval_cfg)\n",
    "samples, ts = sampler.sample(model, num_samples, 100, conditioner, )\n",
    "samples = descramble(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:01<00:00, 203.61it/s]\n"
     ]
    }
   ],
   "source": [
    "# -------------- Sample the model ------------------\n",
    "num_samples = 5\n",
    "test_data_idx = 2\n",
    "conditioner = torch.from_numpy(test_dataset[test_data_idx, 0:condition_dim]).to(device).view(1, condition_dim)\n",
    "conditioner = conditioner.repeat(num_samples, 1)\n",
    "\n",
    "# play around with the sampler by overriding some configs\n",
    "# eval_cfg.sampler.balancing_function = \"birthdeath\"\n",
    "# eval_cfg.sampler.corrector_step_size_multiplier = 1.\n",
    "\n",
    "# sampler = sampling_utils.get_sampler(eval_cfg)\n",
    "# sampler = ConditionalTauLeaping(eval_cfg)\n",
    "sampler = ConditionalGillespies(eval_cfg)\n",
    "samples, ts = sampler.sample(model, num_samples, 100, conditioner)\n",
    "samples = descramble(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 256)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, hist = sampler.sample(model, num_samples, 100, conditioner)\n",
    "x_hist, x0_hist = hist[\"x\"], hist[\"x0\"]\n",
    "samples, x_hist, x0_hist = descramble(samples), descramble(x_hist), descramble(x0_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<lib.sampling.sampling.ConditionalPCTauLeapingAbsorbingInformed at 0x7f94a6860730>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 0\n",
    "plt.scatter(np.arange(256), samples[2, :], alpha=0.3)\n",
    "# plt.scatter(np.arange(256), samples[1, :], alpha=0.3)\n",
    "# plt.scatter(np.arange(256), samples[2, :], alpha=0.3)\n",
    "plt.scatter(np.arange(256), descrambled_test_dataset[test_data_idx, :], alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_hist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36258/3717864079.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m99\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_hist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_hist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_hist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x_hist' is not defined"
     ]
    }
   ],
   "source": [
    "t = 99\n",
    "plt.scatter(np.arange(224), x_hist[t, 0], alpha=0.3)\n",
    "plt.scatter(np.arange(224), x_hist[t, 1], alpha=0.3)\n",
    "plt.scatter(np.arange(224), x_hist[t, 2], alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23842151167343786\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(hellinger(samples[4, condition_dim:], descrambled_test_dataset[test_data_idx, condition_dim:]))\n",
    "print(outliers(samples[4, condition_dim:], descrambled_test_dataset[test_data_idx, condition_dim:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample one sequence for each test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3707175398062234 0.11546875\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3711175906218024 0.11662109375\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.37023999723028744 0.11446614583333334\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3742979789320714 0.119150390625\n",
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3738329625602685 0.1185546875\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3754565989831902 0.12227213541666666\n",
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.37441568642786877 0.12208705357142857\n",
      "700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.37409939580473744 0.122900390625\n",
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.37179775346367844 0.11940538194444444\n",
      "900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:05<00:00, 39.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3748716860979322 0.12049556783144913\n",
      "ConditionalPCTauLeapingAbsorbingInformed\n",
      "Hellinger distance 0.3748716860979322\n",
      "Proportion of outliers 0.12049556783144913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tqdm._instances.clear()\n",
    "batch_size = 100\n",
    "\n",
    "# eval_cfg.sampler.name = \"ConditionalPCTauLeapingAbsorbingInformed\"\n",
    "# eval_cfg.sampler.balancing_function = \"birthdeath\"\n",
    "# eval_cfg.sampler.num_steps = 500\n",
    "# eval_cfg.sampler.corrector_step_size_multiplier = 0.5\n",
    "eval_cfg.sampler.num_corrector_steps = 1\n",
    "eval_cfg.sampler.corrector_entry_time = 0.9\n",
    "eval_cfg.sampler.corrector_step_size_multiplier = .2\n",
    "eval_cfg.sampler.balancing_function = \"barker\"\n",
    "\n",
    "# sampler = sampling_utils.get_sampler(eval_cfg)\n",
    "sampler = ConditionalGillespies(eval_cfg)\n",
    "test_size = test_dataset.shape[0]\n",
    "h_dists = []\n",
    "outlier_proportions = []\n",
    "for start in range(0, test_size, batch_size):\n",
    "    print(start)\n",
    "    end = min(start + batch_size, test_size)\n",
    "    size = end - start\n",
    "    \n",
    "    conditioner = torch.from_numpy(test_dataset[start:end, :condition_dim]).to(device)\n",
    "    samples, _ = sampler.sample(model, size, 1, conditioner, updates_per_eval=2)\n",
    "    samples = descramble(samples)\n",
    "\n",
    "    for i in range(size):\n",
    "        h = hellinger(descrambled_test_dataset[start+i, :], samples[i, :])\n",
    "        r = outliers(descrambled_test_dataset[start+i, :], samples[i, :])\n",
    "        h_dists.append(h)\n",
    "        outlier_proportions.append(r)\n",
    "        \n",
    "    print(\"batch:\", np.mean(h_dists), np.mean(outlier_proportions))\n",
    "        \n",
    "print(eval_cfg.sampler.name)\n",
    "print(\"Hellinger distance\", np.mean(h_dists))\n",
    "print(\"Proportion of outliers\", np.mean(outlier_proportions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.36839183507166096 0.11203125\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.36749378018312556 0.11287109375\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3673050709870709 0.1133203125\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3720713136406303 0.118095703125\n",
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3722532665894587 0.1181328125\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.37355208874377077 0.12198567708333333\n",
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3737981490824307 0.12232700892857143\n",
      "700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3740336213325731 0.1241015625\n",
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3725635302528838 0.12112413194444445\n",
      "900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:05<00:00, 39.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.37605804322262487 0.12308099948612539\n",
      "Hellinger distance 0.37605804322262487\n",
      "Proportion of outliers 0.12308099948612539\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.35954674111224155 0.1055859375\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3671184555040304 0.1142578125\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 29.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.36809687333108126 0.11403645833333333\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.37452054291330056 0.1191015625\n",
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3744757099398966 0.1186875\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3749249620680407 0.12125651041666667\n",
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.37413589179613993 0.12076450892857143\n",
      "700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.37401155269339176 0.1227880859375\n",
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3720914170537288 0.12008246527777777\n",
      "900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:05<00:00, 39.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.375651326948952 0.12185251798561152\n",
      "Hellinger distance 0.375651326948952\n",
      "Proportion of outliers 0.12185251798561152\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.37100265103153957 0.1141796875\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.37344351121878105 0.11763671875\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.37179914898344485 0.11608072916666666\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.375513059533872 0.1205859375\n",
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3747844875355479 0.1207265625\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.37578759601824235 0.12329427083333333\n",
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.37522180158347657 0.123046875\n",
      "700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3756784259029527 0.124814453125\n",
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3737462978704444 0.12170572916666667\n",
      "900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:05<00:00, 38.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3774043236554384 0.1231372045220966\n",
      "Hellinger distance 0.3774043236554384\n",
      "Proportion of outliers 0.1231372045220966\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3644869728667571 0.111328125\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.36819564219621215 0.1165625\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.36997567716151175 0.11498697916666667\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3753191952138144 0.120185546875\n",
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.37564328386567053 0.120375\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3771159453266117 0.12282552083333333\n",
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3753122972826001 0.12182477678571428\n",
      "700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3750790201007436 0.122939453125\n",
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3730420239210404 0.11993923611111111\n",
      "900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:05<00:00, 39.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3759250593922216 0.12070031474820143\n",
      "Hellinger distance 0.3759250593922216\n",
      "Proportion of outliers 0.12070031474820143\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3711468291748934 0.1092578125\n",
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3726021390753276 0.11453125\n",
      "200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.37233675353546547 0.11381510416666667\n",
      "300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3778293168057957 0.119873046875\n",
      "400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.37676788155380947 0.1189375\n",
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 29.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3770745066636248 0.12181640625\n",
      "600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.377267634630964 0.12247209821428572\n",
      "700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.37698233335859904 0.124443359375\n",
      "800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:07<00:00, 30.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3754196597298964 0.12149305555555556\n",
      "900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 224/224 [00:05<00:00, 39.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0.3781195802568118 0.12193281089414183\n",
      "Hellinger distance 0.3781195802568118\n",
      "Proportion of outliers 0.12193281089414183\n",
      "------------------------------\n",
      "Result summary over 5 runs:\n",
      "Hellinger distance: 0.37663166669520975pm0.0009591964691363689\n",
      "Proportion of outliers: 0.12214076952723536pm0.0009031235562586983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "\n",
    "updates_per_eval = 2\n",
    "\n",
    "eval_cfg.sampler.num_corrector_steps = 1\n",
    "eval_cfg.sampler.corrector_entry_time = 0.9\n",
    "eval_cfg.sampler.corrector_step_size_multiplier = .2\n",
    "eval_cfg.sampler.balancing_function = \"barker\"\n",
    "\n",
    "# eval_cfg.sampler.num_corrector_steps = 1\n",
    "# eval_cfg.sampler.corrector_entry_time = 0.9\n",
    "# eval_cfg.sampler.corrector_step_size_multiplier = .1\n",
    "# eval_cfg.sampler.balancing_function = \"birthdeath\"\n",
    "\n",
    "sampler = ConditionalGillespies(eval_cfg)\n",
    "test_size = test_dataset.shape[0]\n",
    "\n",
    "all_h_dists = []\n",
    "all_outlier_proportions = []\n",
    "\n",
    "num_repeats = 5\n",
    "\n",
    "tqdm._instances.clear()\n",
    "\n",
    "for _ in range(num_repeats):\n",
    "    h_dists = []\n",
    "    outlier_proportions = []\n",
    "    for start in range(0, test_size, batch_size):\n",
    "        print(start)\n",
    "        end = min(start + batch_size, test_size)\n",
    "        size = end - start\n",
    "        \n",
    "        conditioner = torch.from_numpy(test_dataset[start:end, :condition_dim]).to(device)\n",
    "        samples, _ = sampler.sample(model, size, 1, conditioner, \n",
    "                                    updates_per_eval=updates_per_eval)\n",
    "        samples = descramble(samples)\n",
    "        for i in range(size):\n",
    "            h = hellinger(descrambled_test_dataset[start+i, :], samples[i, :])\n",
    "            r = outliers(descrambled_test_dataset[start+i, :], samples[i, :])\n",
    "            h_dists.append(h)\n",
    "            outlier_proportions.append(r)\n",
    "        print(\"batch:\", np.mean(h_dists), np.mean(outlier_proportions))\n",
    "            \n",
    "    print(\"Hellinger distance\", np.mean(h_dists))\n",
    "    print(\"Proportion of outliers\", np.mean(outlier_proportions))\n",
    "    all_h_dists.append(np.mean(h_dists))\n",
    "    all_outlier_proportions.append(np.mean(outlier_proportions))\n",
    "\n",
    "print(\"------------------------------\")\n",
    "print(\"Result summary over {} runs:\".format(num_repeats))\n",
    "print(\"Hellinger distance: {}pm{}\".format(np.mean(all_h_dists), np.std(all_h_dists)))\n",
    "print(\"Proportion of outliers: {}pm{}\".format(np.mean(all_outlier_proportions), \n",
    "                                              np.std(all_outlier_proportions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reg transformer, 3Gillespies 1ForwardBackward\n",
    "# Result summary over 5 runs:\n",
    "# Hellinger distance: 0.3757996870517339pm0.0014687256325569174\n",
    "# Proportion of outliers: 0.12672308581706065pm0.0009465965242336641"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reg transformer, 1Gillespies\n",
    "# Result summary over 5 runs:\n",
    "# Hellinger distance: 0.3737476854935375pm0.00039314107832395627\n",
    "# Proportion of outliers: 0.12352903391572456pm0.0010288232129788825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HollowTransformer, 3Gillespies1MPF\n",
    "# Result summary over 5 runs:\n",
    "# Hellinger distance: 0.374410925623968pm0.0006068406145371651\n",
    "# Proportion of outliers: 0.10731388103802672pm0.001071086333231973"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HollowTransformer, 2Gillespies1Barker(.2 rate)\n",
    "# Result summary over 5 runs:\n",
    "# Hellinger distance: 0.37663166669520975pm0.0009591964691363689\n",
    "# Proportion of outliers: 0.12214076952723536pm0.0009031235562586983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HollowTransformer, 1Gillespies\n",
    "# Result summary over 5 runs:\n",
    "# Hellinger distance: 0.37623923435865125pm0.0016456965783516663\n",
    "# Proportion of outliers: 0.12239770683453237pm0.001163738725492646"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HollowTransformer (deep), 2Gillespies1MPF(.05rate)\n",
    "# Result summary over 5 runs:\n",
    "# Hellinger distance: 0.3767222809039338pm0.0004504722377853942\n",
    "# Proportion of outliers: 0.10441691289825283pm0.0008855656271487037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HollowTransformer (deep), 3Gillespies1MPF\n",
    "# Result summary over 5 runs:\n",
    "# Hellinger distance: 0.37741502807366767pm0.0010161391671844433\n",
    "# Proportion of outliers: 0.10295959660842754pm0.0010606355871867193"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HollowTransformer (deep), 1Gillespies\n",
    "# Result summary over 5 runs:\n",
    "# Hellinger distance: 0.37566751329488485pm0.0006240929477967039\n",
    "# Proportion of outliers: 0.12277267471736897pm0.0007224193533914502"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hollow architecture\n",
    "# 0.3780593881848551\n",
    "# 0.12651352132579652"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d812279b1f0eba895e4e8fd2794363aa6926394d8f60a753ee1f119ab02f570b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
