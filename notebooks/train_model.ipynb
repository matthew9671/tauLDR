{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2845c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "# sys.path.remove(\"/home/users/yixiuz/.local/lib/python3.9/site-packages\")\n",
    "sys.path.append(\"/home/groups/swl1/yixiuz/torch_fid/lib/python3.9/site-packages\")\n",
    "sys.path.append(\"/home/groups/swl1/yixiuz/torch_fid/bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a786f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "509e9dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reload(dataset_utils)\n",
    "# reload(datasets)\n",
    "# reload(countdown)\n",
    "# reload(piano)\n",
    "# reload(losses_utils)\n",
    "# reload(losses)\n",
    "# reload(model_utils)\n",
    "# reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e9127",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-13 23:04:28.721554: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-13 23:04:28.835167: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /share/software/user/open/cudnn/8.9.0.131/lib:/usr/lib64/nvidia:/share/software/user/open/cuda/12.2.0/targets/x86_64-linux/lib:/share/software/user/open/cuda/12.2.0/lib64:/share/software/user/open/cuda/12.2.0/nvvm/lib64:/share/software/user/open/cuda/12.2.0/extras/Debugger/lib64:/share/software/user/open/cuda/12.2.0/extras/CUPTI/lib64:/share/software/user/open/python/3.9.0/lib:/share/software/user/open/libffi/3.2.1/lib64:/share/software/user/open/sqlite/3.44.2/lib:/share/software/user/open/readline/8.2/lib:/share/software/user/open/ncurses/6.4/lib:/share/software/user/open/tcltk/8.6.6/lib:/share/software/user/open/libressl/3.2.1/lib:/share/software/user/open/zlib/1.2.11/lib\n",
      "2024-05-13 23:04:28.835206: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-13 23:04:30.149398: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /share/software/user/open/cudnn/8.9.0.131/lib:/usr/lib64/nvidia:/share/software/user/open/cuda/12.2.0/targets/x86_64-linux/lib:/share/software/user/open/cuda/12.2.0/lib64:/share/software/user/open/cuda/12.2.0/nvvm/lib64:/share/software/user/open/cuda/12.2.0/extras/Debugger/lib64:/share/software/user/open/cuda/12.2.0/extras/CUPTI/lib64:/share/software/user/open/python/3.9.0/lib:/share/software/user/open/libffi/3.2.1/lib64:/share/software/user/open/sqlite/3.44.2/lib:/share/software/user/open/readline/8.2/lib:/share/software/user/open/ncurses/6.4/lib:/share/software/user/open/tcltk/8.6.6/lib:/share/software/user/open/libressl/3.2.1/lib:/share/software/user/open/zlib/1.2.11/lib\n",
      "2024-05-13 23:04:30.149567: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /share/software/user/open/cudnn/8.9.0.131/lib:/usr/lib64/nvidia:/share/software/user/open/cuda/12.2.0/targets/x86_64-linux/lib:/share/software/user/open/cuda/12.2.0/lib64:/share/software/user/open/cuda/12.2.0/nvvm/lib64:/share/software/user/open/cuda/12.2.0/extras/Debugger/lib64:/share/software/user/open/cuda/12.2.0/extras/CUPTI/lib64:/share/software/user/open/python/3.9.0/lib:/share/software/user/open/libffi/3.2.1/lib64:/share/software/user/open/sqlite/3.44.2/lib:/share/software/user/open/readline/8.2/lib:/share/software/user/open/ncurses/6.4/lib:/share/software/user/open/tcltk/8.6.6/lib:/share/software/user/open/libressl/3.2.1/lib:/share/software/user/open/zlib/1.2.11/lib\n",
      "2024-05-13 23:04:30.149578: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with config piano_test\n",
      "number of parameters:  7020290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:08<00:00, 11.03it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.96it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.98it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.98it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.98it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.97it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.96it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.96it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.96it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.95it/s]\n",
      "100%|██████████| 94/94 [00:08<00:00, 11.43it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.97it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.97it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.97it/s]\n",
      " 38%|███▊      | 36/94 [00:02<00:04, 12.94it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import ml_collections\n",
    "import yaml\n",
    "import lib.utils.bookkeeping as bookkeeping\n",
    "from pathlib import Path\n",
    "import torch.utils.tensorboard as tensorboard\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import signal\n",
    "import argparse\n",
    "\n",
    "\n",
    "import lib.models.models as models\n",
    "import lib.models.model_utils as model_utils\n",
    "import lib.datasets.datasets as datasets\n",
    "import lib.datasets.dataset_utils as dataset_utils\n",
    "import lib.losses.losses as losses\n",
    "import lib.losses.losses_utils as losses_utils\n",
    "import lib.training.training as training\n",
    "import lib.training.training_utils as training_utils\n",
    "import lib.optimizers.optimizers as optimizers\n",
    "import lib.optimizers.optimizers_utils as optimizers_utils\n",
    "import lib.loggers.loggers as loggers\n",
    "import lib.loggers.logger_utils as logger_utils\n",
    "\n",
    "# import config.train.countdown as countdown\n",
    "# cfg = countdown.get_config()\n",
    "\n",
    "import config.train.piano_hollow as piano\n",
    "cfg = piano.get_config()\n",
    "\n",
    "custom_name = None\n",
    "\n",
    "print(\"Training with config\", cfg.experiment_name)\n",
    "\n",
    "preempted_path = Path(\"null\")\n",
    "if cfg.saving.enable_preemption_recovery:\n",
    "\n",
    "    preempted_path = bookkeeping.check_for_preempted_run(cfg.save_location,\n",
    "        cfg.saving.preemption_start_day_YYYYhyphenMMhyphenDD,\n",
    "        cfg,\n",
    "        cfg.saving.prepare_to_resume_after_timeout\n",
    "    )\n",
    "\n",
    "if preempted_path.as_posix() == \"null\":\n",
    "    save_dir, checkpoint_dir, config_dir = \\\n",
    "        bookkeeping.create_experiment_folder(\n",
    "            cfg.save_location,\n",
    "            cfg.experiment_name if custom_name is None else custom_name,\n",
    "            custom_name is None\n",
    "    )\n",
    "    bookkeeping.save_config_as_yaml(cfg, config_dir)\n",
    "\n",
    "    # bookkeeping.save_git_hash(save_dir)\n",
    "\n",
    "else:\n",
    "    print(\"Resuming from preempted run: \", preempted_path)\n",
    "    save_dir = preempted_path\n",
    "    checkpoint_dir, config_dir = bookkeeping.create_inner_experiment_folders(save_dir)\n",
    "\n",
    "writer = bookkeeping.setup_tensorboard(save_dir, 0)\n",
    "\n",
    "device = torch.device(cfg.device)\n",
    "\n",
    "model = model_utils.create_model(cfg, device)\n",
    "print(\"number of parameters: \", sum([p.numel() for p in model.parameters()]))\n",
    "\n",
    "dataset = dataset_utils.get_dataset(cfg, device)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "    batch_size=cfg.data.batch_size,\n",
    "    shuffle=cfg.data.shuffle)\n",
    "\n",
    "loss = losses_utils.get_loss(cfg)\n",
    "\n",
    "training_step = training_utils.get_train_step(cfg)\n",
    "\n",
    "optimizer = optimizers_utils.get_optimizer(model.parameters(), cfg)\n",
    "\n",
    "state = {\n",
    "    'model': model,\n",
    "    'optimizer': optimizer,\n",
    "    'n_iter': 0\n",
    "}\n",
    "\n",
    "bookkeeping.setup_preemption(save_dir, checkpoint_dir, state,\n",
    "    cfg.saving.num_checkpoints_to_keep,\n",
    "    cfg.saving.prepare_to_resume_after_timeout)\n",
    "\n",
    "\n",
    "if not preempted_path.as_posix() == 'null':\n",
    "    state = bookkeeping.resume_training(preempted_path, state, cfg.device)\n",
    "\n",
    "low_freq_loggers = []\n",
    "for logger in cfg.saving.low_freq_loggers:\n",
    "    low_freq_loggers.append(logger_utils.get_logger(logger))\n",
    "\n",
    "exit_flag = False\n",
    "\n",
    "\n",
    "while True:\n",
    "    for minibatch in tqdm(dataloader):\n",
    "\n",
    "        training_step.step(state, minibatch, loss, writer)\n",
    "\n",
    "        if state['n_iter'] % cfg.saving.checkpoint_freq == 0 or state['n_iter'] == cfg.training.n_iters-1:\n",
    "            bookkeeping.save_checkpoint(checkpoint_dir, state,\n",
    "                cfg.saving.num_checkpoints_to_keep)\n",
    "\n",
    "        if state['n_iter'] % cfg.saving.log_low_freq == 0 or state['n_iter'] == cfg.training.n_iters-1:\n",
    "            for logger in low_freq_loggers:\n",
    "                logger(state=state, cfg=cfg, writer=writer,\n",
    "                       minibatch=minibatch, dataset=dataset)\n",
    "\n",
    "        state['n_iter'] += 1\n",
    "        if state['n_iter'] > cfg.training.n_iters - 1:\n",
    "            exit_flag = True\n",
    "            break\n",
    "\n",
    "    if exit_flag:\n",
    "        break\n",
    "\n",
    "writer.close()\n",
    "\n",
    "return save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f7b9cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
