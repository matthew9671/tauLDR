{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2845c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "# sys.path.remove(\"/home/users/yixiuz/.local/lib/python3.9/site-packages\")\n",
    "sys.path.append(\"/home/groups/swl1/yixiuz/torch_fid/lib/python3.9/site-packages\")\n",
    "sys.path.append(\"/home/groups/swl1/yixiuz/torch_fid/bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "02a786f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "509e9dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config.train.genes_base' from '../config/train/genes_base.py'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload(dataset_utils)\n",
    "# reload(datasets)\n",
    "# reload(countdown)\n",
    "# reload(piano)\n",
    "# reload(losses_utils)\n",
    "# reload(losses)\n",
    "# reload(model_utils)\n",
    "# reload(models)\n",
    "reload(genes)\n",
    "# reload(aemet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "227e9127",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with config genes_baseline_deeper\n",
      "number of parameters:  7130049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 290/5000 [00:32<08:41,  9.03it/s]\n",
      "100%|█████████▉| 4997/5000 [02:40<00:00, 33.31it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import ml_collections\n",
    "import yaml\n",
    "import lib.utils.bookkeeping as bookkeeping\n",
    "from pathlib import Path\n",
    "import torch.utils.tensorboard as tensorboard\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import signal\n",
    "import argparse\n",
    "\n",
    "import lib.models.models as models\n",
    "import lib.models.model_utils as model_utils\n",
    "import lib.datasets.datasets as datasets\n",
    "import lib.datasets.dataset_utils as dataset_utils\n",
    "import lib.losses.losses as losses\n",
    "import lib.losses.losses_utils as losses_utils\n",
    "import lib.training.training as training\n",
    "import lib.training.training_utils as training_utils\n",
    "import lib.optimizers.optimizers as optimizers\n",
    "import lib.optimizers.optimizers_utils as optimizers_utils\n",
    "import lib.loggers.loggers as loggers\n",
    "import lib.loggers.logger_utils as logger_utils\n",
    "\n",
    "# import config.train.countdown_long_hollow as countdown\n",
    "# cfg = countdown.get_config()\n",
    "\n",
    "# import config.train.piano_hollow as piano\n",
    "# cfg = piano.get_config()\n",
    "\n",
    "import config.train.genes_base as genes\n",
    "cfg = genes.get_config()\n",
    "\n",
    "# import config.train.aemet_hollow as aemet\n",
    "# cfg = aemet.get_config()\n",
    "\n",
    "custom_name = None\n",
    "\n",
    "print(\"Training with config\", cfg.experiment_name)\n",
    "\n",
    "preempted_path = Path(\"null\")\n",
    "if cfg.saving.enable_preemption_recovery:\n",
    "\n",
    "    preempted_path = bookkeeping.check_for_preempted_run(cfg.save_location,\n",
    "        cfg.saving.preemption_start_day_YYYYhyphenMMhyphenDD,\n",
    "        cfg,\n",
    "        cfg.saving.prepare_to_resume_after_timeout\n",
    "    )\n",
    "\n",
    "if preempted_path.as_posix() == \"null\":\n",
    "    save_dir, checkpoint_dir, config_dir = \\\n",
    "        bookkeeping.create_experiment_folder(\n",
    "            cfg.save_location,\n",
    "            cfg.experiment_name if custom_name is None else custom_name,\n",
    "            custom_name is None\n",
    "    )\n",
    "    bookkeeping.save_config_as_yaml(cfg, config_dir)\n",
    "\n",
    "    # bookkeeping.save_git_hash(save_dir)\n",
    "\n",
    "else:\n",
    "    print(\"Resuming from preempted run: \", preempted_path)\n",
    "    save_dir = preempted_path\n",
    "    checkpoint_dir, config_dir = bookkeeping.create_inner_experiment_folders(save_dir)\n",
    "\n",
    "writer = bookkeeping.setup_tensorboard(save_dir, 0)\n",
    "\n",
    "device = torch.device(cfg.device)\n",
    "\n",
    "model = model_utils.create_model(cfg, device)\n",
    "print(\"number of parameters: \", sum([p.numel() for p in model.parameters()]))\n",
    "\n",
    "dataset = dataset_utils.get_dataset(cfg, device)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "    batch_size=cfg.data.batch_size,\n",
    "    shuffle=cfg.data.shuffle)\n",
    "\n",
    "loss = losses_utils.get_loss(cfg)\n",
    "\n",
    "training_step = training_utils.get_train_step(cfg)\n",
    "\n",
    "optimizer = optimizers_utils.get_optimizer(model.parameters(), cfg)\n",
    "\n",
    "state = {\n",
    "    'model': model,\n",
    "    'optimizer': optimizer,\n",
    "    'n_iter': 0\n",
    "}\n",
    "\n",
    "bookkeeping.setup_preemption(save_dir, checkpoint_dir, state,\n",
    "    cfg.saving.num_checkpoints_to_keep,\n",
    "    cfg.saving.prepare_to_resume_after_timeout)\n",
    "\n",
    "\n",
    "if not preempted_path.as_posix() == 'null':\n",
    "    state = bookkeeping.resume_training(preempted_path, state, cfg.device)\n",
    "\n",
    "low_freq_loggers = []\n",
    "for logger in cfg.saving.low_freq_loggers:\n",
    "    low_freq_loggers.append(logger_utils.get_logger(logger))\n",
    "\n",
    "exit_flag = False\n",
    "\n",
    "pbar = tqdm(total=cfg.training.n_iters)\n",
    "\n",
    "tqdm._instances.clear()\n",
    "\n",
    "while True:\n",
    "    for minibatch in dataloader:\n",
    "\n",
    "        training_step.step(state, minibatch, loss, writer)\n",
    "\n",
    "        if state['n_iter'] % cfg.saving.checkpoint_freq == 0 or state['n_iter'] == cfg.training.n_iters-1:\n",
    "            bookkeeping.save_checkpoint(checkpoint_dir, state,\n",
    "                cfg.saving.num_checkpoints_to_keep)\n",
    "\n",
    "        if state['n_iter'] % cfg.saving.log_low_freq == 0 or state['n_iter'] == cfg.training.n_iters-1:\n",
    "            for logger in low_freq_loggers:\n",
    "                logger(state=state, cfg=cfg, writer=writer,\n",
    "                       minibatch=minibatch, dataset=dataset)\n",
    "\n",
    "        state['n_iter'] += 1\n",
    "        pbar.update(1)\n",
    "        if state['n_iter'] > cfg.training.n_iters - 1:\n",
    "            exit_flag = True\n",
    "            break\n",
    "\n",
    "    if exit_flag:\n",
    "        break\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5336231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
