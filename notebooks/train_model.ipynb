{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2845c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "# sys.path.remove(\"/home/users/yixiuz/.local/lib/python3.9/site-packages\")\n",
    "sys.path.append(\"/home/groups/swl1/yixiuz/torch_fid/lib/python3.9/site-packages\")\n",
    "sys.path.append(\"/home/groups/swl1/yixiuz/torch_fid/bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a786f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "509e9dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lib.models.models' from '../lib/models/models.py'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload(dataset_utils)\n",
    "# reload(datasets)\n",
    "# reload(countdown)\n",
    "# reload(losses_utils)\n",
    "# reload(losses)\n",
    "# reload(model_utils)\n",
    "# reload(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227e9127",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-07 20:34:29.229161: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-07 20:34:29.345681: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /share/software/user/open/cudnn/8.9.0.131/lib:/usr/lib64/nvidia:/share/software/user/open/cuda/12.2.0/targets/x86_64-linux/lib:/share/software/user/open/cuda/12.2.0/lib64:/share/software/user/open/cuda/12.2.0/nvvm/lib64:/share/software/user/open/cuda/12.2.0/extras/Debugger/lib64:/share/software/user/open/cuda/12.2.0/extras/CUPTI/lib64:/share/software/user/open/python/3.9.0/lib:/share/software/user/open/libffi/3.2.1/lib64:/share/software/user/open/sqlite/3.44.2/lib:/share/software/user/open/readline/8.2/lib:/share/software/user/open/ncurses/6.4/lib:/share/software/user/open/tcltk/8.6.6/lib:/share/software/user/open/libressl/3.2.1/lib:/share/software/user/open/zlib/1.2.11/lib\n",
      "2024-05-07 20:34:29.345725: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-05-07 20:34:30.914726: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /share/software/user/open/cudnn/8.9.0.131/lib:/usr/lib64/nvidia:/share/software/user/open/cuda/12.2.0/targets/x86_64-linux/lib:/share/software/user/open/cuda/12.2.0/lib64:/share/software/user/open/cuda/12.2.0/nvvm/lib64:/share/software/user/open/cuda/12.2.0/extras/Debugger/lib64:/share/software/user/open/cuda/12.2.0/extras/CUPTI/lib64:/share/software/user/open/python/3.9.0/lib:/share/software/user/open/libffi/3.2.1/lib64:/share/software/user/open/sqlite/3.44.2/lib:/share/software/user/open/readline/8.2/lib:/share/software/user/open/ncurses/6.4/lib:/share/software/user/open/tcltk/8.6.6/lib:/share/software/user/open/libressl/3.2.1/lib:/share/software/user/open/zlib/1.2.11/lib\n",
      "2024-05-07 20:34:30.914830: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /share/software/user/open/cudnn/8.9.0.131/lib:/usr/lib64/nvidia:/share/software/user/open/cuda/12.2.0/targets/x86_64-linux/lib:/share/software/user/open/cuda/12.2.0/lib64:/share/software/user/open/cuda/12.2.0/nvvm/lib64:/share/software/user/open/cuda/12.2.0/extras/Debugger/lib64:/share/software/user/open/cuda/12.2.0/extras/CUPTI/lib64:/share/software/user/open/python/3.9.0/lib:/share/software/user/open/libffi/3.2.1/lib64:/share/software/user/open/sqlite/3.44.2/lib:/share/software/user/open/readline/8.2/lib:/share/software/user/open/ncurses/6.4/lib:/share/software/user/open/tcltk/8.6.6/lib:/share/software/user/open/libressl/3.2.1/lib:/share/software/user/open/zlib/1.2.11/lib\n",
      "2024-05-07 20:34:30.914839: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with config countdown_test\n",
      "number of parameters:  5318433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:14<00:00,  6.90it/s]\n",
      "100%|██████████| 100/100 [00:13<00:00,  7.63it/s]\n",
      "100%|██████████| 100/100 [00:41<00:00,  2.38it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.54it/s]\n",
      "100%|██████████| 100/100 [00:13<00:00,  7.57it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.56it/s]\n",
      "100%|██████████| 100/100 [00:16<00:00,  6.04it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.55it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.54it/s]\n",
      "100%|██████████| 100/100 [00:22<00:00,  4.41it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.12it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.63it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.61it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  7.84it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.62it/s]\n",
      "100%|██████████| 100/100 [00:18<00:00,  5.53it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.59it/s]\n",
      "100%|██████████| 100/100 [00:15<00:00,  6.51it/s]\n",
      "100%|██████████| 100/100 [00:43<00:00,  2.30it/s]\n",
      "100%|██████████| 100/100 [00:24<00:00,  4.10it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.10it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.06it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.54it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.05it/s]\n",
      "100%|██████████| 100/100 [00:13<00:00,  7.29it/s]\n",
      "100%|██████████| 100/100 [00:28<00:00,  3.47it/s]\n",
      "100%|██████████| 100/100 [00:15<00:00,  6.49it/s]\n",
      "100%|██████████| 100/100 [00:13<00:00,  7.15it/s]\n",
      "100%|██████████| 100/100 [00:19<00:00,  5.17it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.74it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.25it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.74it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.76it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.74it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.73it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.27it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.74it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.74it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.77it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.76it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.77it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.76it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.27it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.77it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.73it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.77it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.03it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.73it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.40it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.55it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  7.91it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  7.95it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.52it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.57it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.50it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.50it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.57it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.56it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.51it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.53it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.56it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.09it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.51it/s]\n",
      "100%|██████████| 100/100 [00:13<00:00,  7.15it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.56it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.52it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.52it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.60it/s]\n",
      "100%|██████████| 100/100 [00:17<00:00,  5.78it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.63it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.77it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.25it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.74it/s]\n",
      "100%|██████████| 100/100 [00:38<00:00,  2.63it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.74it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.77it/s]\n",
      "100%|██████████| 100/100 [00:15<00:00,  6.37it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.18it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.76it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.77it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.25it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.77it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.76it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.74it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.74it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.76it/s]\n",
      "100%|██████████| 100/100 [00:48<00:00,  2.07it/s]\n",
      "100%|██████████| 100/100 [00:43<00:00,  2.31it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.72it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.74it/s]\n",
      "100%|██████████| 100/100 [00:22<00:00,  4.42it/s]\n",
      "100%|██████████| 100/100 [00:43<00:00,  2.28it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.77it/s]\n",
      "100%|██████████| 100/100 [00:30<00:00,  3.24it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:23<00:00,  4.18it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  7.96it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:21<00:00,  4.70it/s]\n",
      "100%|██████████| 100/100 [00:22<00:00,  4.39it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.74it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.74it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.74it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.76it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.28it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.73it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.74it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.76it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.74it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.75it/s]\n",
      "100%|██████████| 100/100 [00:27<00:00,  3.64it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.74it/s]\n",
      "100%|██████████| 100/100 [00:11<00:00,  8.77it/s]\n",
      "100%|██████████| 100/100 [00:12<00:00,  8.28it/s]\n",
      "100%|██████████| 100/100 [00:31<00:00,  3.20it/s]\n",
      " 42%|████▏     | 42/100 [00:23<00:33,  1.72it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import ml_collections\n",
    "import yaml\n",
    "import lib.utils.bookkeeping as bookkeeping\n",
    "from pathlib import Path\n",
    "import torch.utils.tensorboard as tensorboard\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import signal\n",
    "import argparse\n",
    "\n",
    "\n",
    "import lib.models.models as models\n",
    "import lib.models.model_utils as model_utils\n",
    "import lib.datasets.datasets as datasets\n",
    "import lib.datasets.dataset_utils as dataset_utils\n",
    "import lib.losses.losses as losses\n",
    "import lib.losses.losses_utils as losses_utils\n",
    "import lib.training.training as training\n",
    "import lib.training.training_utils as training_utils\n",
    "import lib.optimizers.optimizers as optimizers\n",
    "import lib.optimizers.optimizers_utils as optimizers_utils\n",
    "import lib.loggers.loggers as loggers\n",
    "import lib.loggers.logger_utils as logger_utils\n",
    "\n",
    "import config.train.countdown as countdown\n",
    "cfg = countdown.get_config()\n",
    "\n",
    "custom_name = None\n",
    "\n",
    "print(\"Training with config\", cfg.experiment_name)\n",
    "\n",
    "preempted_path = Path(\"null\")\n",
    "if cfg.saving.enable_preemption_recovery:\n",
    "\n",
    "    preempted_path = bookkeeping.check_for_preempted_run(cfg.save_location,\n",
    "        cfg.saving.preemption_start_day_YYYYhyphenMMhyphenDD,\n",
    "        cfg,\n",
    "        cfg.saving.prepare_to_resume_after_timeout\n",
    "    )\n",
    "\n",
    "if preempted_path.as_posix() == \"null\":\n",
    "    save_dir, checkpoint_dir, config_dir = \\\n",
    "        bookkeeping.create_experiment_folder(\n",
    "            cfg.save_location,\n",
    "            cfg.experiment_name if custom_name is None else custom_name,\n",
    "            custom_name is None\n",
    "    )\n",
    "    bookkeeping.save_config_as_yaml(cfg, config_dir)\n",
    "\n",
    "    # bookkeeping.save_git_hash(save_dir)\n",
    "\n",
    "else:\n",
    "    print(\"Resuming from preempted run: \", preempted_path)\n",
    "    save_dir = preempted_path\n",
    "    checkpoint_dir, config_dir = bookkeeping.create_inner_experiment_folders(save_dir)\n",
    "\n",
    "writer = bookkeeping.setup_tensorboard(save_dir, 0)\n",
    "\n",
    "device = torch.device(cfg.device)\n",
    "\n",
    "model = model_utils.create_model(cfg, device)\n",
    "print(\"number of parameters: \", sum([p.numel() for p in model.parameters()]))\n",
    "\n",
    "dataset = dataset_utils.get_dataset(cfg, device)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "    batch_size=cfg.data.batch_size,\n",
    "    shuffle=cfg.data.shuffle)\n",
    "\n",
    "loss = losses_utils.get_loss(cfg)\n",
    "\n",
    "training_step = training_utils.get_train_step(cfg)\n",
    "\n",
    "optimizer = optimizers_utils.get_optimizer(model.parameters(), cfg)\n",
    "\n",
    "state = {\n",
    "    'model': model,\n",
    "    'optimizer': optimizer,\n",
    "    'n_iter': 0\n",
    "}\n",
    "\n",
    "bookkeeping.setup_preemption(save_dir, checkpoint_dir, state,\n",
    "    cfg.saving.num_checkpoints_to_keep,\n",
    "    cfg.saving.prepare_to_resume_after_timeout)\n",
    "\n",
    "\n",
    "if not preempted_path.as_posix() == 'null':\n",
    "    state = bookkeeping.resume_training(preempted_path, state, cfg.device)\n",
    "\n",
    "low_freq_loggers = []\n",
    "for logger in cfg.saving.low_freq_loggers:\n",
    "    low_freq_loggers.append(logger_utils.get_logger(logger))\n",
    "\n",
    "exit_flag = False\n",
    "\n",
    "\n",
    "while True:\n",
    "    for minibatch in tqdm(dataloader):\n",
    "\n",
    "        training_step.step(state, minibatch, loss, writer)\n",
    "\n",
    "        if state['n_iter'] % cfg.saving.checkpoint_freq == 0 or state['n_iter'] == cfg.training.n_iters-1:\n",
    "            bookkeeping.save_checkpoint(checkpoint_dir, state,\n",
    "                cfg.saving.num_checkpoints_to_keep)\n",
    "\n",
    "        if state['n_iter'] % cfg.saving.log_low_freq == 0 or state['n_iter'] == cfg.training.n_iters-1:\n",
    "            for logger in low_freq_loggers:\n",
    "                logger(state=state, cfg=cfg, writer=writer,\n",
    "                       minibatch=minibatch, dataset=dataset)\n",
    "\n",
    "        state['n_iter'] += 1\n",
    "        if state['n_iter'] > cfg.training.n_iters - 1:\n",
    "            exit_flag = True\n",
    "            break\n",
    "\n",
    "    if exit_flag:\n",
    "        break\n",
    "\n",
    "writer.close()\n",
    "\n",
    "return save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeadeb3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
