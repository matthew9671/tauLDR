{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2845c6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "# sys.path.remove(\"/home/users/yixiuz/.local/lib/python3.9/site-packages\")\n",
    "sys.path.append(\"/home/groups/swl1/yixiuz/torch_fid/lib/python3.9/site-packages\")\n",
    "sys.path.append(\"/home/groups/swl1/yixiuz/torch_fid/bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227e9127",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 16:45:01.420979: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-30 16:45:01.538312: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /share/software/user/open/cudnn/8.9.0.131/lib:/usr/lib64/nvidia:/share/software/user/open/cuda/12.2.0/targets/x86_64-linux/lib:/share/software/user/open/cuda/12.2.0/lib64:/share/software/user/open/cuda/12.2.0/nvvm/lib64:/share/software/user/open/cuda/12.2.0/extras/Debugger/lib64:/share/software/user/open/cuda/12.2.0/extras/CUPTI/lib64:/share/software/user/open/python/3.9.0/lib:/share/software/user/open/libffi/3.2.1/lib64:/share/software/user/open/sqlite/3.44.2/lib:/share/software/user/open/readline/8.2/lib:/share/software/user/open/ncurses/6.4/lib:/share/software/user/open/tcltk/8.6.6/lib:/share/software/user/open/libressl/3.2.1/lib:/share/software/user/open/zlib/1.2.11/lib\n",
      "2024-04-30 16:45:01.538360: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-04-30 16:45:04.647662: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /share/software/user/open/cudnn/8.9.0.131/lib:/usr/lib64/nvidia:/share/software/user/open/cuda/12.2.0/targets/x86_64-linux/lib:/share/software/user/open/cuda/12.2.0/lib64:/share/software/user/open/cuda/12.2.0/nvvm/lib64:/share/software/user/open/cuda/12.2.0/extras/Debugger/lib64:/share/software/user/open/cuda/12.2.0/extras/CUPTI/lib64:/share/software/user/open/python/3.9.0/lib:/share/software/user/open/libffi/3.2.1/lib64:/share/software/user/open/sqlite/3.44.2/lib:/share/software/user/open/readline/8.2/lib:/share/software/user/open/ncurses/6.4/lib:/share/software/user/open/tcltk/8.6.6/lib:/share/software/user/open/libressl/3.2.1/lib:/share/software/user/open/zlib/1.2.11/lib\n",
      "2024-04-30 16:45:04.647803: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /share/software/user/open/cudnn/8.9.0.131/lib:/usr/lib64/nvidia:/share/software/user/open/cuda/12.2.0/targets/x86_64-linux/lib:/share/software/user/open/cuda/12.2.0/lib64:/share/software/user/open/cuda/12.2.0/nvvm/lib64:/share/software/user/open/cuda/12.2.0/extras/Debugger/lib64:/share/software/user/open/cuda/12.2.0/extras/CUPTI/lib64:/share/software/user/open/python/3.9.0/lib:/share/software/user/open/libffi/3.2.1/lib64:/share/software/user/open/sqlite/3.44.2/lib:/share/software/user/open/readline/8.2/lib:/share/software/user/open/ncurses/6.4/lib:/share/software/user/open/tcltk/8.6.6/lib:/share/software/user/open/libressl/3.2.1/lib:/share/software/user/open/zlib/1.2.11/lib\n",
      "2024-04-30 16:45:04.647816: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with config piano_test\n",
      "number of parameters:  7008769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:08<00:00, 10.92it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.61it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.60it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.27it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.58it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.57it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.60it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.60it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.57it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 11.99it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.60it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.53it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.57it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.57it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.58it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.57it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.58it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.26it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.60it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.63it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.62it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.63it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.61it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.61it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.60it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.60it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.60it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.59it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.27it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.60it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.60it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.61it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.60it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.59it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.60it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.60it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.60it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.61it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.63it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.27it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.58it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.60it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.61it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.64it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.63it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.64it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.64it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.61it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.22it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.57it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.54it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.58it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.57it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.62it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.27it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.63it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.64it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.63it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.60it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.64it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.64it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.65it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.65it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.65it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.65it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.27it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.64it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.62it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.62it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.59it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.63it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.63it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.60it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.57it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.58it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 11.89it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.53it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.54it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.54it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.59it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.24it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.58it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.57it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.57it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.58it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.26it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.58it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.58it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.57it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.59it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.25it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.57it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.57it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.57it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.58it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.23it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.57it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.59it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.58it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.58it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.24it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.54it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.57it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.58it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.59it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.57it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 12.24it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.57it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.58it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.58it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.53it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:07<00:00, 12.23it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.60it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.58it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.55it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:07<00:00, 11.78it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "100%|██████████| 94/94 [00:06<00:00, 14.56it/s]\n",
      "  7%|▋         | 7/94 [00:01<00:20,  4.35it/s]\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/software/user/open/py-jupyter/1.0.0_py39/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3449: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import ml_collections\n",
    "import yaml\n",
    "import lib.utils.bookkeeping as bookkeeping\n",
    "from pathlib import Path\n",
    "import torch.utils.tensorboard as tensorboard\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import signal\n",
    "import argparse\n",
    "\n",
    "\n",
    "import lib.models.models as models\n",
    "import lib.models.model_utils as model_utils\n",
    "import lib.datasets.datasets as datasets\n",
    "import lib.datasets.dataset_utils as dataset_utils\n",
    "import lib.losses.losses as losses\n",
    "import lib.losses.losses_utils as losses_utils\n",
    "import lib.training.training as training\n",
    "import lib.training.training_utils as training_utils\n",
    "import lib.optimizers.optimizers as optimizers\n",
    "import lib.optimizers.optimizers_utils as optimizers_utils\n",
    "import lib.loggers.loggers as loggers\n",
    "import lib.loggers.logger_utils as logger_utils\n",
    "\n",
    "from config.train.piano import get_config\n",
    "cfg = get_config()\n",
    "\n",
    "custom_name = None\n",
    "\n",
    "print(\"Training with config\", cfg.experiment_name)\n",
    "\n",
    "preempted_path = Path(\"null\")\n",
    "if cfg.saving.enable_preemption_recovery:\n",
    "\n",
    "    preempted_path = bookkeeping.check_for_preempted_run(cfg.save_location,\n",
    "        cfg.saving.preemption_start_day_YYYYhyphenMMhyphenDD,\n",
    "        cfg,\n",
    "        cfg.saving.prepare_to_resume_after_timeout\n",
    "    )\n",
    "\n",
    "if preempted_path.as_posix() == \"null\":\n",
    "    save_dir, checkpoint_dir, config_dir = \\\n",
    "        bookkeeping.create_experiment_folder(\n",
    "            cfg.save_location,\n",
    "            cfg.experiment_name if custom_name is None else custom_name,\n",
    "            custom_name is None\n",
    "    )\n",
    "    bookkeeping.save_config_as_yaml(cfg, config_dir)\n",
    "\n",
    "    # bookkeeping.save_git_hash(save_dir)\n",
    "\n",
    "else:\n",
    "    print(\"Resuming from preempted run: \", preempted_path)\n",
    "    save_dir = preempted_path\n",
    "    checkpoint_dir, config_dir = bookkeeping.create_inner_experiment_folders(save_dir)\n",
    "\n",
    "writer = bookkeeping.setup_tensorboard(save_dir, 0)\n",
    "\n",
    "device = torch.device(cfg.device)\n",
    "\n",
    "model = model_utils.create_model(cfg, device)\n",
    "print(\"number of parameters: \", sum([p.numel() for p in model.parameters()]))\n",
    "\n",
    "dataset = dataset_utils.get_dataset(cfg, device)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "    batch_size=cfg.data.batch_size,\n",
    "    shuffle=cfg.data.shuffle)\n",
    "\n",
    "loss = losses_utils.get_loss(cfg)\n",
    "\n",
    "training_step = training_utils.get_train_step(cfg)\n",
    "\n",
    "optimizer = optimizers_utils.get_optimizer(model.parameters(), cfg)\n",
    "\n",
    "state = {\n",
    "    'model': model,\n",
    "    'optimizer': optimizer,\n",
    "    'n_iter': 0\n",
    "}\n",
    "\n",
    "bookkeeping.setup_preemption(save_dir, checkpoint_dir, state,\n",
    "    cfg.saving.num_checkpoints_to_keep,\n",
    "    cfg.saving.prepare_to_resume_after_timeout)\n",
    "\n",
    "\n",
    "if not preempted_path.as_posix() == 'null':\n",
    "    state = bookkeeping.resume_training(preempted_path, state, cfg.device)\n",
    "\n",
    "low_freq_loggers = []\n",
    "for logger in cfg.saving.low_freq_loggers:\n",
    "    low_freq_loggers.append(logger_utils.get_logger(logger))\n",
    "\n",
    "exit_flag = False\n",
    "\n",
    "\n",
    "while True:\n",
    "    for minibatch in tqdm(dataloader):\n",
    "\n",
    "        training_step.step(state, minibatch, loss, writer)\n",
    "\n",
    "        if state['n_iter'] % cfg.saving.checkpoint_freq == 0 or state['n_iter'] == cfg.training.n_iters-1:\n",
    "            bookkeeping.save_checkpoint(checkpoint_dir, state,\n",
    "                cfg.saving.num_checkpoints_to_keep)\n",
    "\n",
    "        if state['n_iter'] % cfg.saving.log_low_freq == 0 or state['n_iter'] == cfg.training.n_iters-1:\n",
    "            for logger in low_freq_loggers:\n",
    "                logger(state=state, cfg=cfg, writer=writer,\n",
    "                       minibatch=minibatch, dataset=dataset)\n",
    "\n",
    "        state['n_iter'] += 1\n",
    "        if state['n_iter'] > cfg.training.n_iters - 1:\n",
    "            exit_flag = True\n",
    "            break\n",
    "\n",
    "    if exit_flag:\n",
    "        break\n",
    "\n",
    "writer.close()\n",
    "\n",
    "return save_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7c4423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We're specifically training on the pianoroll dataset here\n",
    "\n",
    "main(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
